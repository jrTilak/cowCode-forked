/**
 * Vision executor: describe or analyze an image using a vision-capable LLM.
 * Image: file path (browse screenshot, user upload), URL, data URI, or live webcam.
 * Built-in chaining: screenshot → vision → browse (click/fill/scroll). Live camera: image "webcam" captures from default webcam.
 */

import { readFileSync, existsSync } from 'fs';
import { describeImage } from '../../llm.js';

function pathToDataUri(filepath) {
  const buf = readFileSync(filepath);
  const ext = (filepath.split('.').pop() || '').toLowerCase();
  const mime = ext === 'png' ? 'image/png' : ext === 'gif' ? 'image/gif' : ext === 'webp' ? 'image/webp' : 'image/jpeg';
  const base64 = buf.toString('base64');
  return `data:${mime};base64,${base64}`;
}

/**
 * Capture one frame from the default webcam via Playwright (getUserMedia → canvas → data URL).
 * @returns {Promise<string>} data URI (image/jpeg)
 */
async function captureWebcamFrame() {
  const { chromium } = await import('playwright');
  const browser = await chromium.launch({
    headless: true,
    args: ['--use-fake-ui-for-media-stream', '--autoplay-policy=no-user-gesture-required'],
  });
  try {
    const context = await browser.newContext({
      permissions: ['camera'],
      ignoreHTTPSErrors: true,
    });
    const page = await context.newPage();
    const dataUrl = await page.evaluate(async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
      const video = document.createElement('video');
      video.srcObject = stream;
      video.muted = true;
      video.playsInline = true;
      await new Promise((resolve, reject) => {
        video.onloadeddata = () => resolve();
        video.onerror = () => reject(new Error('Video failed to load'));
        video.play().catch(reject);
      });
      await new Promise((r) => setTimeout(r, 300));
      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(video, 0, 0);
      stream.getTracks().forEach((t) => t.stop());
      return canvas.toDataURL('image/jpeg', 0.9);
    });
    await browser.close();
    if (!dataUrl || !dataUrl.startsWith('data:image/')) throw new Error('Webcam capture did not return an image');
    return dataUrl;
  } finally {
    await browser.close().catch(() => {});
  }
}

/**
 * @param {object} ctx - unused
 * @param {object} args - LLM tool args: image (path, URL, "webcam"), source ("webcam"), prompt (optional)
 * @returns {Promise<string>}
 */
export async function executeVision(ctx, args) {
  const source = (args?.source && String(args.source).trim().toLowerCase()) === 'webcam';
  let image = args?.image != null ? String(args.image).trim() : (args?.url && String(args.url).trim());
  if (source || (image && image.toLowerCase() === 'webcam')) {
    image = await captureWebcamFrame();
  }
  if (!image) throw new Error('vision requires "image" or "url" (file path, URL, or data URI), or "source": "webcam" / image: "webcam" for live camera');

  let imageInput;
  if (image.startsWith('http://') || image.startsWith('https://')) {
    imageInput = image;
  } else if (image.startsWith('data:image/')) {
    imageInput = image;
  } else {
    if (!existsSync(image)) throw new Error(`Image file not found: ${image}`);
    imageInput = pathToDataUri(image);
  }

  const prompt = (args?.prompt && String(args.prompt).trim()) || 'Describe what you see in this image. If there is text, read it.';
  const systemPrompt = (args?.systemPrompt && String(args.systemPrompt).trim()) || 'You are a helpful vision assistant. Describe or analyze the image concisely. If the user asked a specific question, answer it.';

  return describeImage(imageInput, prompt, systemPrompt);
}
